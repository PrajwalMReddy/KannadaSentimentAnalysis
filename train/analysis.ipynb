{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import re\n",
    "import string"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer, tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from translate import Translator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Global Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "minLikes = 10000000\n",
    "maxLikes = 0\n",
    "\n",
    "minReplies = 10000000\n",
    "maxReplies = 0\n",
    "\n",
    "minRetweets = 10000000\n",
    "maxRetweets = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Data Class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "class CandidatePair:\n",
    "    def __init__(self, candidate1, candidate2, predicted1, predicted2):\n",
    "        self.candidate1 = candidate1\n",
    "        self.candidate2 = candidate2\n",
    "        self.predicted1 = predicted1\n",
    "        self.predicted2 = predicted2\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.candidate1}: {self.predicted1} | {self.candidate2}: {self.predicted2} {'✔️' if self.is_correct_prediction() else '❌'}\"\n",
    "\n",
    "    def is_correct_prediction(self):\n",
    "        if self.predicted1 > self.predicted2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def margin_of_victory(self):\n",
    "        return self.predicted1 - self.predicted2\n",
    "\n",
    "    def percent_margin_of_victory(self):\n",
    "        total = self.predicted1 + self.predicted2\n",
    "        return ((self.predicted1 - self.predicted2) / total) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Method To Find All Politicians Whose Tweets Are Available\n",
    "\n",
    "def get_politicians():\n",
    "    path = \"tweets-train\"\n",
    "    folders = [folder for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder))]\n",
    "\n",
    "    for folder in folders:\n",
    "        yield folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Method To Find All The Available Tweets From A Given Politician\n",
    "\n",
    "def get_politicians_tweets(politician):\n",
    "    global maxLikes\n",
    "    global minLikes\n",
    "\n",
    "    global maxReplies\n",
    "    global minReplies\n",
    "\n",
    "    global maxRetweets\n",
    "    global minRetweets\n",
    "\n",
    "    path = f\"tweets-train/{politician}\"\n",
    "    tweets = []\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                if data[\"Likes\"] > maxLikes:\n",
    "                    maxLikes = data[\"Likes\"]\n",
    "                elif data[\"Likes\"] < minLikes:\n",
    "                    minLikes = data[\"Likes\"]\n",
    "\n",
    "                if data[\"Replies\"] > maxReplies:\n",
    "                    maxReplies = data[\"Replies\"]\n",
    "                elif data[\"Replies\"] < minReplies:\n",
    "                    minReplies = data[\"Replies\"]\n",
    "\n",
    "                if data[\"Retweets\"] > maxRetweets:\n",
    "                    maxRetweets = data[\"Retweets\"]\n",
    "                elif data[\"Retweets\"] < minRetweets:\n",
    "                    minRetweets = data[\"Retweets\"]\n",
    "\n",
    "                tweets.append(data)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def store_results(results):\n",
    "    with open(\"./results.json\", \"w+\") as file:\n",
    "        json.dump(results, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions For Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = tokenize.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    filtered_text = [word for word in words if not word in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def sentiment_polarity(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    score = sia.polarity_scores(sanitize_text(text))\n",
    "    key = list(score.keys())[list(score.values()).index(max(list(score.values())[:len(score) - 1]))]\n",
    "\n",
    "    return score, key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def translate_text(json_tweet):\n",
    "    if json_tweet[\"Language\"] != \"kn\":\n",
    "        return json_tweet[\"Tweet\"]\n",
    "\n",
    "    # TODO Add: from_lang='kn',\n",
    "    # This Slows Down The Analysis Though\n",
    "    translator = Translator(to_lang=\"en\")\n",
    "    translation = translator.translate(json_tweet[\"Tweet\"])\n",
    "\n",
    "    return translation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Core Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(json_tweet):\n",
    "    text = json_tweet[\"Tweet\"]\n",
    "\n",
    "    if json_tweet[\"Language\"] != \"en\":\n",
    "        text = translate_text(json_tweet)\n",
    "\n",
    "    score, key = sentiment_polarity(text)\n",
    "\n",
    "    # The Sentiment Polarity Is Worth 25% Of The Total Score\n",
    "    # The Sentiment Polarity Also Cannot Be Negative\n",
    "    sent_pol = (score[\"pos\"] - score[\"neg\"]) if (score[\"pos\"] - score[\"neg\"]) > 0 else 0\n",
    "\n",
    "    likes_score = (json_tweet[\"Likes\"] - minLikes) / (maxLikes - minLikes)  # Scales The Likes Score To The Range Of 0.0 to 1.0\n",
    "    replies_score = (json_tweet[\"Replies\"] - minReplies) / (maxReplies - minReplies)  # Scales The Replies Score To The Range Of 0.0 to 1.0\n",
    "    retweets_score = (json_tweet[\"Retweets\"] - minRetweets) / (maxRetweets - minRetweets)  # Scales The Retweets Score To The Range Of 0.0 to 1.0\n",
    "\n",
    "    # The Final Total Score Is From 0.0 to 100.0\n",
    "    total_score = 25 * (sent_pol + likes_score + replies_score + retweets_score)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_politician(politician):\n",
    "    total_score = 0\n",
    "    tweet_count = 0\n",
    "    all_politicians_tweets = get_politicians_tweets(politician)\n",
    "\n",
    "    for tweet in all_politicians_tweets:\n",
    "        total_score += calculate_score(tweet)\n",
    "        tweet_count += 1\n",
    "\n",
    "    avg_score = total_score / tweet_count if tweet_count != 0 else 0\n",
    "\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze():\n",
    "    scores = {}\n",
    "    all_politicians = get_politicians()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            politician = next(all_politicians)\n",
    "            scores.update({ politician: analyze_politician(politician) })\n",
    "\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "    store_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def conclude():\n",
    "    with open(\"./settings.json\", 'r', encoding=\"utf-8\") as file:\n",
    "        settings = json.load(file)\n",
    "\n",
    "    with open(\"./results.json\", 'r', encoding=\"utf-8\") as file:\n",
    "        results = json.load(file)\n",
    "\n",
    "    candidates = settings[\"Candidates\"]\n",
    "    candidatePairs = []\n",
    "\n",
    "    for i in range(0, len(candidates), 2):\n",
    "        if candidates[i][\"Name\"] in results.keys() and candidates[i + 1][\"Name\"] in results.keys():\n",
    "            candidatePairs.append(\n",
    "                CandidatePair(candidates[i][\"Name\"], candidates[i + 1][\"Name\"], results[candidates[i][\"Name\"]],\n",
    "                              results[candidates[i + 1][\"Name\"]]))\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(candidatePairs)\n",
    "\n",
    "    total_margin = 0\n",
    "    total_percent_margin = 0\n",
    "\n",
    "    print(\"All Predicted Pairs:\")\n",
    "    for pair in candidatePairs:\n",
    "        print(pair)\n",
    "\n",
    "        total_margin += pair.margin_of_victory()\n",
    "        total_percent_margin += pair.percent_margin_of_victory()\n",
    "\n",
    "        if pair.is_correct_prediction():\n",
    "            correct_predictions += 1\n",
    "\n",
    "    print(\n",
    "        f\"\\nResults:\\n\"\n",
    "        f\"Total Correct Pairs: {correct_predictions}\\n\"\n",
    "        f\"Total Pairs: {total_predictions}\\n\"\n",
    "        f\"Average Net Margin: {(total_margin / total_predictions) if total_predictions != 0 else 0}\\n\"\n",
    "        f\"Average Percent Margin: {(total_percent_margin / total_predictions) if total_predictions != 0 else 0}%\\n\"\n",
    "        f\"Accuracy: {(correct_predictions / total_predictions) * 100 if total_predictions != 0 else 0}%\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code Entry Point"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Predicted Pairs:\n",
      "Lalaji Mendon: 2.085752557242642 | Vinay Kumar Sorake: 6.192461927255472 ❌\n",
      "GT Devegowda: 0.6742550770090997 | Siddaramaiah: 12.94892934851243 ❌\n",
      "H.D. Kumaraswamy: 7.886256433081359 | C. P. Yogeeshwara: 3.937035187035187 ✔️\n",
      "G. H. Thippareddy: 1.0186923390317515 | K. C. Veerendra: 0.1483655913113867 ✔️\n",
      "L. Nagendra: 1.8753433162863238 | Vasu: 1.802165116297996 ✔️\n",
      "Dr. C.N. Ashwath Narayan: 3.5200746784923593 | Kengal Shreepadha Renu: 2.090565903929211 ✔️\n",
      "Dinesh Gundu Rao: 14.619258746642867 | A. R. Sapthagiri Gowda: 8.771435413245758 ✔️\n",
      "Ramalinga Reddy: 2.6806889614592877 | Lallesh Reddy: 2.7877859873631183 ❌\n",
      "Munirathna: 1.7586124907453564 | P. Muniraju Gowda: 1.5053311300879688 ✔️\n",
      "Suresha BS: 3.142705881269143 | Y. A. Narayanaswamy: 5.13208177491688 ❌\n",
      "C. Puttarangashetty: 3.1350554058101223 | K. R. Mallikarjunappa: 0.0033922026914259265 ✔️\n",
      "\n",
      "Results:\n",
      "Total Correct Pairs: 7\n",
      "Total Pairs: 11\n",
      "Average Net Margin: -0.26571397232513827\n",
      "Average Percent Margin: 9.298134835911357%\n",
      "Accuracy: 63.63636363636363%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    analyze()\n",
    "    conclude()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e358ab14436f20fa8adfe44b92a4021a1658e80e4db4753088016b8d9937371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
