{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import re\n",
    "import string"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer, tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from translate import Translator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Global Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "minLikes = 10000000\n",
    "maxLikes = 0\n",
    "\n",
    "minReplies = 10000000\n",
    "maxReplies = 0\n",
    "\n",
    "minRetweets = 10000000\n",
    "maxRetweets = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Data Class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class PredictedCandidatePair:\n",
    "    def __init__(self, candidate1, candidate2, predicted1, predicted2):\n",
    "        self.candidate1 = candidate1\n",
    "        self.candidate2 = candidate2\n",
    "        self.predicted1 = predicted1\n",
    "        self.predicted2 = predicted2\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.predicted1 > self.predicted2:\n",
    "            return f\"{self.candidate1} | {self.predicted1} Is More Likely To Win Than {self.candidate2} | {self.predicted2} ({self.predicted_percent_margin_of_victory()}% Confidence)\"\n",
    "        elif self.predicted2 > self.predicted1:\n",
    "            return f\"{self.candidate2} | {self.predicted2} Is More Likely To Win Than {self.candidate1} | {self.predicted1} ({self.predicted_percent_margin_of_victory()}% Confidence)\"\n",
    "\n",
    "    def predicted_margin_of_victory(self):\n",
    "        return self.predicted1 - self.predicted2\n",
    "\n",
    "    def predicted_percent_margin_of_victory(self):\n",
    "        total = self.predicted1 + self.predicted2\n",
    "        return (abs(self.predicted1 - self.predicted2) / total) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Method To Find All Politicians Whose Tweets Are Available\n",
    "\n",
    "def get_politicians():\n",
    "    path = \"tweets-test\"\n",
    "    folders = [folder for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder))]\n",
    "\n",
    "    for folder in folders:\n",
    "        yield folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Method To Find All The Available Tweets From A Given Politician\n",
    "\n",
    "def get_politicians_tweets(politician):\n",
    "    global maxLikes\n",
    "    global minLikes\n",
    "\n",
    "    global maxReplies\n",
    "    global minReplies\n",
    "\n",
    "    global maxRetweets\n",
    "    global minRetweets\n",
    "\n",
    "    path = f\"tweets-test/{politician}\"\n",
    "    tweets = []\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                if data[\"Likes\"] > maxLikes:\n",
    "                    maxLikes = data[\"Likes\"]\n",
    "                elif data[\"Likes\"] < minLikes:\n",
    "                    minLikes = data[\"Likes\"]\n",
    "\n",
    "                if data[\"Replies\"] > maxReplies:\n",
    "                    maxReplies = data[\"Replies\"]\n",
    "                elif data[\"Replies\"] < minReplies:\n",
    "                    minReplies = data[\"Replies\"]\n",
    "\n",
    "                if data[\"Retweets\"] > maxRetweets:\n",
    "                    maxRetweets = data[\"Retweets\"]\n",
    "                elif data[\"Retweets\"] < minRetweets:\n",
    "                    minRetweets = data[\"Retweets\"]\n",
    "\n",
    "                tweets.append(data)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def store_results(results):\n",
    "    with open(\"./results.json\", \"w+\") as file:\n",
    "        json.dump(results, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions For Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = tokenize.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    filtered_text = [word for word in words if not word in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def sentiment_polarity(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    score = sia.polarity_scores(sanitize_text(text))\n",
    "    key = list(score.keys())[list(score.values()).index(max(list(score.values())[:len(score) - 1]))]\n",
    "\n",
    "    return score, key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def translate_text(json_tweet):\n",
    "    if json_tweet[\"Language\"] != \"kn\":\n",
    "        return json_tweet[\"Tweet\"]\n",
    "\n",
    "    translator = Translator(from_lang='kn', to_lang=\"en\")\n",
    "    translation = translator.translate(json_tweet[\"Tweet\"])\n",
    "\n",
    "    return translation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Core Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(json_tweet):\n",
    "    text = json_tweet[\"Tweet\"]\n",
    "\n",
    "    if json_tweet[\"Language\"] != \"en\":\n",
    "        text = translate_text(json_tweet)\n",
    "\n",
    "    score, key = sentiment_polarity(text)\n",
    "\n",
    "    sent_pol = (score[\"pos\"] - score[\"neg\"]) if (score[\"pos\"] - score[\"neg\"]) > 0 else 0  # Ensures The Sentiment Polarity Is Positive\n",
    "    likes_score = (json_tweet[\"Likes\"] - minLikes) / (maxLikes - minLikes)  # Scales The Likes Score To The Range Of 0.0 to 1.0\n",
    "    replies_score = (json_tweet[\"Replies\"] - minReplies) / (maxReplies - minReplies)  # Scales The Replies Score To The Range Of 0.0 to 1.0\n",
    "    retweets_score = (json_tweet[\"Retweets\"] - minRetweets) / (maxRetweets - minRetweets)  # Scales The Retweets Score To The Range Of 0.0 to 1.0\n",
    "\n",
    "    # The Final Total Score Is From 0.0 to 100.0\n",
    "    total_score = 25 * (sent_pol + likes_score + replies_score + retweets_score)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_politician(politician):\n",
    "    total_score = 0\n",
    "    tweet_count = 0\n",
    "    all_politicians_tweets = get_politicians_tweets(politician)\n",
    "\n",
    "    for tweet in all_politicians_tweets:\n",
    "        total_score += calculate_score(tweet)\n",
    "        tweet_count += 1\n",
    "\n",
    "    avg_score = total_score / tweet_count if tweet_count != 0 else 0\n",
    "\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze():\n",
    "    scores = {}\n",
    "    all_politicians = get_politicians()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            politician = next(all_politicians)\n",
    "            scores.update({ politician: analyze_politician(politician) })\n",
    "\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "    store_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def conclude():\n",
    "    with open(\"./settings.json\", 'r', encoding=\"utf-8\") as file:\n",
    "        settings = json.load(file)\n",
    "\n",
    "    with open(\"./results.json\", 'r', encoding=\"utf-8\") as file:\n",
    "        results = json.load(file)\n",
    "\n",
    "    candidates = settings[\"Candidates\"]\n",
    "    candidatePairs = []\n",
    "\n",
    "    for i in range(0, len(candidates), 2):\n",
    "        if candidates[i][\"Name\"] in results.keys() and candidates[i + 1][\"Name\"] in results.keys():\n",
    "            candidatePairs.append(\n",
    "                PredictedCandidatePair(candidates[i][\"Name\"], candidates[i + 1][\"Name\"], results[candidates[i][\"Name\"]], results[candidates[i + 1][\"Name\"]])\n",
    "            )\n",
    "\n",
    "    total_predictions = len(candidatePairs)\n",
    "    total_predicted_margin = 0\n",
    "    total_predicted_percent_margin = 0\n",
    "\n",
    "    print(\"All Predicted Pairs:\")\n",
    "    for pair in candidatePairs:\n",
    "        print(pair)\n",
    "\n",
    "        total_predicted_margin += pair.predicted_margin_of_victory()\n",
    "        total_predicted_percent_margin += pair.predicted_percent_margin_of_victory()\n",
    "\n",
    "    print(\n",
    "        f\"\\nResults:\\n\"\n",
    "        f\"Total Pairs: {total_predictions}\\n\"\n",
    "        f\"Average Predicted Net Margin: {(total_predicted_margin / total_predictions) if total_predictions != 0 else 0}\\n\"\n",
    "        f\"Average Predicted Percent Margin: {(total_predicted_percent_margin / total_predictions) if total_predictions != 0 else 0}%\\n\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code Entry Point"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Predicted Pairs:\n",
      "Ravi Subramanya L. A | 4.77654655750704 Is More Likely To Win Than UB Venkatesh | 1.0745990524108924 (63.26876396343981% Confidence)\n",
      "C.P. Yogeeshwara | 26.13252688172043 Is More Likely To Win Than H. D. Kumaraswamy | 3.445504753987188 (76.70227149376868% Confidence)\n",
      "D. K. Shivakumar | 26.830414738909372 Is More Likely To Win Than R. Ashoka | 2.429866912390995 (83.39136347798615% Confidence)\n",
      "Siddaramaiah | 25.088561166091928 Is More Likely To Win Than V. Somanna | 8.827401734702175 (47.94544527293671% Confidence)\n",
      "M. Krishnappa | 1.0495744237436155 Is More Likely To Win Than H. Ravindra | 0.9307659049408527 (5.99939904681368% Confidence)\n",
      "\n",
      "Results:\n",
      "Total Pairs: 5\n",
      "Average Predicted Net Margin: 13.38637367438695\n",
      "Average Predicted Percent Margin: 55.461448650989%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    analyze()\n",
    "    conclude()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e358ab14436f20fa8adfe44b92a4021a1658e80e4db4753088016b8d9937371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
